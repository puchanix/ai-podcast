// index.js with tap-and-hold (mobile) and click-to-toggle (desktop) voice recording
// All previous logic preserved (Da Vinci, podcast, status, questions, UI)
// dummy change

import { useEffect, useRef, useState } from "react";
import { personas } from "../lib/personas";

export default function Home() {
  const [selectedPersona, setSelectedPersona] = useState("daVinci");
  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isThinking, setIsThinking] = useState(false);
  const [statusMessage, setStatusMessage] = useState("");
  const [isPodcastPlaying, setIsPodcastPlaying] = useState(false);
  const [hasStarted, setHasStarted] = useState(false);
  const [isDaVinciSpeaking, setIsDaVinciSpeaking] = useState(false);
  const [daVinciPaused, setDaVinciPaused] = useState(false);
  const [popularQuestions, setPopularQuestions] = useState([]);
  const mimeType = useRef(""); // put this with other useRef declarations
  

 

  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);
  const filename = useRef("input.webm");

  const podcastAudio = useRef(null);
  const daVinciAudio = useRef(null);

  const isTouchDevice = false; // Treat all devices the same

  const handleTouchStart = () => {
    if (isTouchDevice && !isRecording && !isThinking) startRecording();
  };

  const handleTouchEnd = () => {
    if (isTouchDevice && isRecording && mediaRecorderRef.current?.state === "recording") {
      mediaRecorderRef.current.stop();
    }
  };

  const handleClickRecord = () => {
    if (!isTouchDevice) {
      if (!isRecording) {
        startRecording();
      } else {
        mediaRecorderRef.current?.stop();
      }
    }
  };

  const fetchPopularQuestions = async () => {
    try {
      const res = await fetch(`/api/question-count?character=${selectedPersona}`);
      const data = await res.json();
      setPopularQuestions(data.questions || []);
    } catch (err) {
      console.error("Failed to fetch popular questions", err);
    }
  };

  useEffect(() => {
    fetchPopularQuestions();
  }, [selectedPersona]);

  useEffect(() => {
    if (typeof navigator !== 'undefined' && navigator.permissions && navigator.mediaDevices) {
      navigator.permissions.query({ name: "microphone" }).then((res) => {
        if (res.state === "prompt") {
          navigator.mediaDevices.getUserMedia({ audio: true })
            .then((stream) => stream.getTracks().forEach(track => track.stop()))
            .catch(() => {});
        }
      }).catch(() => {});
    }
  }, []);
  

  const recordQuestion = async (question) => {
    if (!question) return;
    try {
      await fetch(`/api/question-count`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ character: selectedPersona, question }),
      });
      await fetchPopularQuestions();
    } catch (err) {
      console.error("Failed to record question click", err);
    }
  };

  useEffect(() => {
    if (typeof navigator !== 'undefined' && navigator.permissions && navigator.mediaDevices) {
      navigator.permissions.query({ name: "microphone" }).then((res) => {
        if (res.state === "prompt") {
          navigator.mediaDevices.getUserMedia({ audio: true })
            .then((stream) => stream.getTracks().forEach(track => track.stop()))
            .catch(() => {});
        }
      }).catch(() => {});
    }
  }, []);

  useEffect(() => {
    if (!isThinking) return;
    const messages = [
      "Pondering your question‚Ä¶",
      "Almost there‚Ä¶",
      "Just a moment more‚Ä¶",
      `${personas[selectedPersona].name} is working on your question‚Ä¶`
    ];
    let idx = 0;
    setStatusMessage(messages[0]);
    const iv = setInterval(() => {
      idx = (idx + 1) % messages.length;
      setStatusMessage(messages[idx]);
    }, 3000);
    return () => clearInterval(iv);
  }, [isThinking, selectedPersona]);

  const unlockAudio = () => {
    const dummy = new Audio("/silent.mp3");
    dummy.play().catch(() => {});
  };

  const stopDaVinci = () => {
    if (daVinciAudio.current) {
      daVinciAudio.current.pause();
      daVinciAudio.current.src = "";
      setIsDaVinciSpeaking(false);
      setDaVinciPaused(true);
    }
  };

  const stopPodcast = () => {
    if (podcastAudio.current && !podcastAudio.current.paused) {
      podcastAudio.current.pause();
      setIsPodcastPlaying(false);
    }
  };

  const startRecording = async () => {
    unlockAudio();
    stopDaVinci();
    stopPodcast();

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mimeType.current = MediaRecorder.isTypeSupported("audio/ogg; codecs=opus")
      ? "audio/ogg; codecs=opus"
      : "audio/webm";

      const recorder = new MediaRecorder(stream, { mimeType: mimeType.current });

      chunksRef.current = [];

      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunksRef.current.push(e.data);
      };

      recorder.onstop = async () => {
        const blob = new Blob(chunksRef.current, { type: mimeType.current });
        console.log("üì¶ Audio blob size:", blob.size, "bytes ‚Äî Chunks:", chunksRef.current.length);

        chunksRef.current = [];

        const formData = new FormData();
        formData.append("audio", blob, filename.current);

        setStatusMessage("üìù Transcribing...");

        try {
          const res = await fetch("/api/transcribe", { method: "POST", body: formData });
          const json = await res.json();
          const transcript = json.text?.trim();
          if (!transcript) throw new Error("No transcript");

          setStatusMessage("üéß Answering...");
          await recordQuestion(transcript);
          handleAsk(transcript);
        } catch (err) {
          console.error("‚ùå Transcription failed:", err);
          setStatusMessage("‚ö†Ô∏è Could not understand your voice.");
        }

        setIsRecording(false);
      };

      recorder.start();
      setIsRecording(true);
      setStatusMessage("üé§ Listening...");

    } catch (err) {
      console.error("Mic error:", err);
      setStatusMessage("‚ùå Mic not supported");
    }
  };

  const handleAsk = async (question) => {
    if (question === "Tell me Your Story") {
      togglePodcast();
      return;
    }
    await recordQuestion(question);
    unlockAudio();
    stopDaVinci();
    stopPodcast();
    setIsThinking(true);
    setDaVinciPaused(false);

    const encoded = encodeURIComponent(question);
    const url = `/api/ask-audio?character=${selectedPersona}&question=${encoded}`;

    const audio = daVinciAudio.current;
    audio.src = url;
    audio.load();
    audio.play()
      .then(() => {
        setIsDaVinciSpeaking(true);
        setIsThinking(false);
        setStatusMessage("");
      })
      .catch((err) => {
        console.error("Playback error:", err);
        setStatusMessage("‚ùå Audio playback failed");
        setIsThinking(false);
      });

    audio.onended = () => {
      setIsDaVinciSpeaking(false);
      setIsThinking(false);
      setStatusMessage("");
    };

    audio.onerror = () => {
      console.error("Audio playback error");
      setStatusMessage("‚ùå Audio playback error");
      setIsThinking(false);
    };
  };

  const togglePodcast = () => {
    if (!podcastAudio.current) return;
    if (podcastAudio.current.paused) {
      podcastAudio.current.src = personas[selectedPersona].podcast;
      podcastAudio.current.play();
      setIsPodcastPlaying(true);
      setHasStarted(true);
    } else {
      podcastAudio.current.pause();
      setIsPodcastPlaying(false);
    }
  };

  const toggleDaVinci = () => {
    const da = daVinciAudio.current;
    if (!da) return;
    if (da.paused) {
      da.play();
      setIsDaVinciSpeaking(true);
      setDaVinciPaused(false);
    } else {
      da.pause();
      setIsDaVinciSpeaking(false);
      setDaVinciPaused(true);
    }
  };

  const uiQuestions = ["Tell me Your Story", ...personas[selectedPersona].questions];

  return (
    <div className="min-h-screen flex flex-col items-center justify-center bg-gradient-to-b from-background-top to-background text-copy p-4 space-y-6 text-center">
      <h1 className="text-3xl sm:text-4xl font-heading font-bold tracking-wide text-heading drop-shadow-sm uppercase">
        Talk to the Heroes of History
      </h1>

      <img
        src={personas[selectedPersona].image}
        alt={personas[selectedPersona].name}
        className="w-32 h-32 rounded-full object-cover shadow-md"
      />

      <select
        value={selectedPersona}
        onChange={(e) => setSelectedPersona(e.target.value)}
        className="mt-2 mb-6 p-2 rounded border border-border text-white bg-dropdown-bg bg-opacity-95 shadow-sm"
      >
        {Object.values(personas).map((p) => (
          <option key={p.id} value={p.id}>
            {p.name}
          </option>
        ))}
      </select>

      <p className="text-neutral-dark font-medium">{statusMessage}</p>

      <div className="flex flex-wrap justify-center gap-3">
        {uiQuestions.map((q, i) => (
          <button
            key={i}
            onClick={() => handleAsk(q)}
            disabled={isThinking}
            className="bg-button-primary hover:bg-button-hover disabled:bg-neutral-dark text-white py-2 px-5 rounded-full shadow-lg transition-all duration-200 ease-in-out"
          >
            {q}
          </button>
        ))}
      </div>

      {!isThinking && !isTranscribing && (


        <button
          onClick={handleClickRecord}
          onTouchStart={handleTouchStart}
          onTouchEnd={handleTouchEnd}
          className="w-[260px] h-12 bg-voice-button text-black font-semibold py-3 px-6 mt-4 rounded-full shadow-lg ring-2 ring-heading hover:ring-offset-2 hover:scale-105 transition-all duration-200"

        >
{isRecording ? "üõë Click when you are done" : "üé§ Click to ask your own question"}

        </button>
      )}

      {(isDaVinciSpeaking || daVinciPaused) && (
        <button
          onClick={toggleDaVinci}
          className="bg-button-primary hover:bg-button-hover text-white py-2 px-5 rounded-full shadow-md"
        >
          {isDaVinciSpeaking ? "‚è∏Ô∏è Pause Response" : "‚ñ∂Ô∏è Resume Response"}
        </button>
      )}

      <div className="mt-10 w-full max-w-md bg-box-accent p-5 rounded-xl shadow-lg border border-border">
        <h2 className="text-heading font-heading font-bold text-lg uppercase tracking-wider drop-shadow-sm opacity-90 mb-4">Popular Questions</h2>
        <div className="space-y-2">
          {popularQuestions.map((item, idx) => (
            <button
              key={idx}
              onClick={() => handleAsk(item.question)}
              className="w-full text-left bg-white hover:bg-neutral-dark py-2 px-3 rounded text-black"
            >
              {item.question}
            </button>
          ))}
        </div>
      </div>

      <audio ref={podcastAudio} hidden preload="auto" />
      <audio ref={daVinciAudio} hidden preload="auto" />
      <audio hidden preload="auto" src="/silent.mp3" />

      <footer className="mt-10 text-sm text-copy-soft">
        <div className="flex space-x-6 justify-center">
          <a href="/about" className="hover:underline">About</a>
          <a href="/feedback" className="hover:underline">Feedback</a>
        </div>
      </footer>
    </div>
  );
}

